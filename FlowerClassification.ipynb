{
  "cells": [
    {
      "metadata": {
        "_uuid": "3a6898fdb7b4536ed857b8305cb20cb4c1a39a49"
      },
      "cell_type": "markdown",
      "source": "The dataset includes Images for 5 types of flowers . The task is to train the model which will be able to classify the flowers based on their images correctly.\n\nThe link for this dataset is - https://www.kaggle.com/alxmamaev/flowers-recognition"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "823e18d4794cc1fcb7298cbf08387b2c73af367b"
      },
      "cell_type": "code",
      "source": "#define file paths.\nimport os\ndaisy_path = \"../input/flowers/flowers/daisy/\"\ndandelion_path = \"../input/flowers/flowers/dandelion/\"\nrose_path = \"../input/flowers/flowers/rose/\"\nsunflower_path = \"../input/flowers/flowers/sunflower/\"\ntulip_path = \"../input/flowers/flowers/tulip/\"\n",
      "execution_count": 31,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "407531dc22e480dc49526785af83b957b151b2e9"
      },
      "cell_type": "markdown",
      "source": "Reading in all the images using cv2 library in memory from their respective folders."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a47d99e49e0ae349f6e874bae810d5cd9e59f188"
      },
      "cell_type": "code",
      "source": "from os import listdir\nimport cv2\nimg_data = []\nlabels = []\n\nsize = 128,128\ndef iter_images(images,directory,size,label):\n    try:\n        for i in range(len(images)):\n            img = cv2.imread(directory + images[i])\n            img = cv2.resize(img,size)\n            img_data.append(img)\n            labels.append(label)\n    except:\n        pass\n\niter_images(listdir(daisy_path),daisy_path,size,0)\niter_images(listdir(dandelion_path),dandelion_path,size,1)\niter_images(listdir(rose_path),rose_path,size,2)\niter_images(listdir(sunflower_path),sunflower_path,size,3)\niter_images(listdir(tulip_path),tulip_path,size,4)",
      "execution_count": 32,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9e114dbd863923c0491ed376d93d4f3f5ecaa123"
      },
      "cell_type": "markdown",
      "source": ""
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f797126ec73bee0d06528ba4dd52e1ab597c8068"
      },
      "cell_type": "code",
      "source": "len(img_data),len(labels)",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 33,
          "data": {
            "text/plain": "(3386, 3386)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "92d6d116209f18b0ef298478693224d2a44cb409"
      },
      "cell_type": "markdown",
      "source": "Checking the data size, confirmining that images and labels are the same."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5525cc49b2157f3118aa821c86caec9783abc93b"
      },
      "cell_type": "code",
      "source": "import numpy as np\ndata = np.asarray(img_data)\n#div by 255\ndata = data.astype('float32') / 255.0\nlabels = np.asarray(labels)",
      "execution_count": 35,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5ae5c7504f4f941e1016f972c918c086b75c41c4"
      },
      "cell_type": "markdown",
      "source": "Checking the shape of the input data channel."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "41c53628117b42155f715e1b9899ac226f2259c7"
      },
      "cell_type": "code",
      "source": "data.shape,labels.shape",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 36,
          "data": {
            "text/plain": "((3386, 128, 128, 3), (3386,))"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3c0d4d639c4b15ba32d2464f70cb117f84c32283"
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\n# Split the data\nx_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, shuffle= True)",
      "execution_count": 37,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3b58f61671bf8b7d51936f6b81e8699305a4a56c"
      },
      "cell_type": "markdown",
      "source": "Creating a test and train split."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a3db5df9abb69ea3c380c13b72beaa680fb33a87"
      },
      "cell_type": "code",
      "source": "from keras.utils import to_categorical\nclasses = 5\ny_train_binary = to_categorical(y_train,classes)\ny_test_binary = to_categorical(y_test,classes)",
      "execution_count": 38,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "19439a65a91d67c27f616a515bbe9e7c5a582911"
      },
      "cell_type": "markdown",
      "source": "Here I define the a sequential convolutional 2 dimensional model, which uses Keras and many hidden layers with relu activations.\nWe train the model for 10 epochs and perform validations on validation dataset."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3f25ce5ac073bf3eec84b1791978fd3e2642470b"
      },
      "cell_type": "code",
      "source": "from keras.models import Sequential\nfrom keras.layers import Conv2D,MaxPool2D,Flatten,Dense\n\nmodel = Sequential()\nmodel.add(Conv2D(32, (3,3),input_shape=(128, 128, 3),activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Flatten())\nmodel.add(Dense(1000,activation='relu'))\nmodel.add(Dense(1000,activation='relu'))\nmodel.add(Dense(1000,activation='relu'))\nmodel.add(Dense(1000,activation='relu'))\nmodel.add(Dense(1000,activation='relu'))\nmodel.add(Dense(1000,activation='relu'))\nmodel.add(Dense(1000,activation='relu'))\nmodel.add(Dense(1000,activation='relu'))\nmodel.add(Dense(5,activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n\nbatch_size = 128\nepochs = 10\nmodel.fit(x_train, y_train_binary,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test, y_test_binary))\n",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Train on 2708 samples, validate on 678 samples\nEpoch 1/10\n2708/2708 [==============================] - 92s 34ms/step - loss: 2.2671 - acc: 0.2840 - val_loss: 1.3246 - val_acc: 0.3968\nEpoch 2/10\n2708/2708 [==============================] - 81s 30ms/step - loss: 1.2820 - acc: 0.4309 - val_loss: 1.3829 - val_acc: 0.3805\nEpoch 3/10\n2708/2708 [==============================] - 80s 30ms/step - loss: 1.1046 - acc: 0.5395 - val_loss: 1.1968 - val_acc: 0.5059\nEpoch 4/10\n2708/2708 [==============================] - 81s 30ms/step - loss: 1.0218 - acc: 0.5739 - val_loss: 1.1713 - val_acc: 0.5678\nEpoch 5/10\n2708/2708 [==============================] - 81s 30ms/step - loss: 0.8095 - acc: 0.6946 - val_loss: 1.2682 - val_acc: 0.5516\nEpoch 6/10\n2708/2708 [==============================] - 82s 30ms/step - loss: 0.6406 - acc: 0.7770 - val_loss: 1.1544 - val_acc: 0.6047\nEpoch 7/10\n2708/2708 [==============================] - 80s 30ms/step - loss: 0.4059 - acc: 0.8612 - val_loss: 1.3409 - val_acc: 0.5870\nEpoch 8/10\n2708/2708 [==============================] - 81s 30ms/step - loss: 0.2518 - acc: 0.9136 - val_loss: 1.6342 - val_acc: 0.5870\nEpoch 9/10\n2708/2708 [==============================] - 80s 30ms/step - loss: 0.1648 - acc: 0.9420 - val_loss: 2.1914 - val_acc: 0.5442\nEpoch 10/10\n2708/2708 [==============================] - 81s 30ms/step - loss: 0.1718 - acc: 0.9542 - val_loss: 1.7951 - val_acc: 0.5796\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 39,
          "data": {
            "text/plain": "<keras.callbacks.History at 0x7fe1656e2358>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "744b9372ffaa8e51e007ed521880a953a8fe8891"
      },
      "cell_type": "markdown",
      "source": "Import the confusion matrix and print the matrix of right and wrong predictions."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8376a295e9bee5c57a7032356bb705c166f1fa9e"
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import confusion_matrix\npred = model.predict_classes(x_test)\ncm = confusion_matrix(y_test, pred)\nprint(cm)",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[[108  11   5  19  17]\n [  9   5   0  10   0]\n [ 49   2  30  17  64]\n [  7   5   0 123  11]\n [ 21   3   9  26 127]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "d678149b15d3571994ed6068ea0e04a7239e3aea"
      },
      "cell_type": "markdown",
      "source": "Print the accuracy."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c1bacc231c2d12b3f60cb12d65c624a28f72210e"
      },
      "cell_type": "code",
      "source": "acc = (cm[0][0]+cm[1][1]+cm[2][2]+cm[3][3]+cm[4][4])/(len(y_test))\nprint('Accuracy =',(acc*100),'%')",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Accuracy = 57.9646017699115 %\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8164a6bfd5706d2ca4c8c0f3834ad23df2043993"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}